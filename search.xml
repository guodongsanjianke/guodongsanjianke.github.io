<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>电流体力学:界面剪切应力作用的综述</title>
    <url>/2022/09/14/10-43-40/</url>
    <content><![CDATA[<h1 id="电流体力学界面剪切应力作用的综述"><strong>电流体力学</strong>:界面剪切应力作用的综述</h1>
<h4 id="标题">标题：</h4>
<h4 id="electrohydrodynamics-a-review-of-the-role-of-interfacial-shear-stresses">Electrohydrodynamics a review of the role of interfacial shear stresses</h4>
<h4 id="范围">范围</h4>
<p>电流体力学可以看作是研究电作用力效应的流体力学分支。它也可以看作是涉及到运动介质对电场影响的电动力学的一部分。实际上，是这两个领域的结合，因为电流体动力学中许多最有趣的问题既涉及流体运动对场的影响，又涉及场对运动的影响。</p>
<p>“电流体力学”一词相对较新;它所代表的面积不是。相关的文献和关于电本身的文献一样令人尊敬。更重要的是，为了引起人们对工程技术的兴趣，没有必要强调该地区巨大的技术前景，因为应用已经形成了主要产业的基础。但几乎所有讨论的中心都是实验的可重复性的缺乏和理论模型的不足。流体中的静电效应以其变幻莫测而闻名;通常，它们非常依赖于电导率，因此研究人员不鼓励仔细地将分析模型和简单的实验联系起来。然而，流体力学的基础是建立在将精心设计的实验与分析模型相联系的工作之上的，我们希望将注意力集中在具有这一目标的电流体力学研究上。皮卡德(1)对这一主题作了历史回顾，在这里不太合适。</p>
<h4 id="电动力学">电动力学</h4>
<p><strong>法则和近似</strong>。有关电学定律的摘要有助于进一步界定我们的主题。electrohydrodynamic交互的一个显著特征是无旋的电场强度,动态电流太小,磁感应是可忽略的,和适当的法则本质上是静电学的总结如表1.2高斯法、方程<span class="math inline">\(Ib\)</span>、与自由电荷密度,<span class="math inline">\(q\)</span>,为电位移<span class="math inline">\(D\)</span>，式<span class="math inline">\(Ic\)</span>在保证电荷守恒的动态方程中引入了自由电流密度。按照惯例，进一步用极化密度<span class="math inline">\(P\)</span>来定义电位移(方程<span class="math inline">\(Id\)</span>)其中<span class="math inline">\(\epsilon_{0}=8.85 \times 10^{-12}\)</span>.</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures2/20220516171129.png" style="zoom:67%;" /></p>
<p>表I的准静态电性定律对伽利略变换(2)是不变的，可以用来表明，在一个以速度<span class="math inline">\(v\)</span>运动的有启动的坐标系中的场如表1中的公式Ie到Ii所示。这些变换将准静态近似隐式地反映到微分定律中。因此，电场和电流密度不像在磁流体动力学近似中那样发生变化，在这种近似中，磁感应是必不可少的，但净电荷是可以忽略的。边界从地区单位法n定向地区(A) (b),支持表面电荷密度<span class="math inline">\(Q\)</span>和表面电流密度<span class="math inline">\(K\)</span>,正常速度<span class="math inline">\(n·v\)</span>, Ij II所描述的条件,发现通过整合微分法在表面和卷,包括边界。(2)条件II的表面电流密度K包括表面电荷对流的贡献，如果合适，还包括表面传导的贡献。</p>
<p><strong>传导和极化</strong>。-表一的准静态方程是用本构定律解释物质运动影响的宏观场表示的。对许多目的,流体静止的传导规律的<span class="math inline">\(J = J * (g, E)\)</span>。受假设加速度不影响传导过程,本法适用于流体运动的脸如果是评估在一个参照系的流体速度<span class="math inline">\(v\)</span>移动,运动我们必须编写<span class="math inline">\(J = J * (q&#39;,E’)\)</span>，由表I中的Ig和Ih方程可知，在实验室框架下，流体运动时的传导规律为 <span class="math display">\[
J=J *(q, E)+q v
\]</span> 方程Ie和Ii表明，如果极化是E的函数，无论从实验室框架还是流体的运动框架来看，都是一样的。当然，在使用转换定律将本构定律推广到物质运动的情况下，隐含的假设是可以忽略对传导和极化的加速效应。</p>
<p><strong>电荷泄漏</strong>. (3)最近报道的研究表明，这种最简单的电导定律可以用来理解范围广得惊人的电流体力学现象。在这篇综述中，注意力主要集中在这个案例上 <span class="math display">\[
J^{*}=\sigma E
\]</span> 给定流体元素的电导率<span class="math inline">\(\sigma\)</span>。此外，我们将简单地将其作为极化本构法 <span class="math display">\[
D=\epsilon \bar{E}
\]</span> 移动的流体粒子的介电常数<span class="math inline">\(\epsilon\)</span>是常数</p>
<p>在均匀不可压缩流体中，<span class="math inline">\(\sigma\)</span>和<span class="math inline">\(\epsilon\)</span>为常数，<span class="math inline">\(\nabla \cdot v=0\)</span>，我们可以对自由电荷密度<span class="math inline">\(q\)</span>的分布得到深远的结论。我们将方程Ib和Ic与方程2和3结合得到 <span class="math display">\[
\left[\frac{\partial}{\partial t}+v \cdot \nabla\right] q+\frac{\sigma}{\epsilon} q=0
\]</span> (r, t)空间中的特征线就是粒子线，因此有 <span class="math display">\[
q=q_{0} e^{-t / \tau} \text { on } \frac{d r}{d t}=v
\]</span> 其中体积弛豫时间<span class="math inline">\(\tau \equiv \epsilon / \sigma\)</span>。因此，给定流体粒子附近的自由电荷密度随弛豫时间<span class="math inline">\(\tau\)</span>衰减。此外，除非流体中的某一给定元素可以通过粒子线追踪到电荷源，否则它将不支持体积电荷密度。</p>
<h4 id="流体力学">流体力学</h4>
<p><strong>运动方程</strong>。-我们只讨论给定流体元素的质量密度<span class="math inline">\(p\)</span>是常数的情况;因此液体，有一个恒定的粘度<span class="math inline">\(\mu\)</span>。受重力加速度<span class="math inline">\(g\)</span>的影响，其压力<span class="math inline">\(p\)</span>和速度<span class="math inline">\(v\)</span>受表二方程的控制。除了机械压力和粘滞应力<span class="math inline">\(T^m\)</span>，还有一个由于自由电荷密度<span class="math inline">\(q\)</span>(促成传导和对流的电荷)和极化而产生的电作用力。边界条件(lId到I If)通过积分动量守恒和质量守恒，方程I Ia-IIc通过界面得到。</p>
<p><strong>电体力</strong>。-不可压缩流体上的电作用力可以正确地用不同的形式书写，这些形式与压力的梯度不同。这是真的，因为在表二的微分定律和隐含的边界条件中，压力<span class="math inline">\(p\)</span>只出现在方程lIb中，并简单地由电诱导压力的加入重新定义。因此，我们忽略电致伸缩力，因为它们可能只对膨胀流体运动有重要意义，并将力密度写成由Korteweg &amp;亥姆霍兹在(4,5) <span class="math display">\[
F=q E-\frac{1}{2} E^{2} \nabla \epsilon
\]</span> 方程6可以写成 <span class="math display">\[
F=\nabla \cdot T^{e} ; \quad T_{i j}{ }^{e}=\epsilon E_{i} E_{j}-\frac{1}{2} \epsilon \delta_{i j} E_{k} E_{k}
\]</span> 麦克斯韦应力张量<span class="math inline">\(T^e\)</span>不仅考虑了由自由电荷引起的力，还考虑了<span class="math inline">\(\epsilon =\epsilon(r, t)\)</span>以及极化引起的力</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures2/20220516174735.png" style="zoom:67%;" /></p>
]]></content>
      <categories>
        <category>果冻的随便写写</category>
      </categories>
      <tags>
        <tag>EHD</tag>
      </tags>
  </entry>
  <entry>
    <title>图神经网络解偏微分方程系列（二）</title>
    <url>/2022/01/05/13-43-40/</url>
    <content><![CDATA[<h1 id="图神经网络解偏微分方程系列二">图神经网络解偏微分方程系列（二）</h1>
<h2 id="标题和概述">1. 标题和概述</h2>
<h3 id="physics-informed-graph-neural-galerkin-networks-a-unified-framework-for-sloving-pde-governed-forward-and-inverse-problems">Physics-informed graph neural Galerkin networks: A unified framework for sloving PDE-governed forward and inverse problems</h3>
<h4 id="基于物理的图galerkin-网络解pde控制的正逆问题的统一框架"><font color=red> 基于物理的图Galerkin 网络：解PDE控制的正逆问题的统一框架</font></h4>
<p>这篇文章名字是基于物理信息的图Galerkin：解PDE控制的正逆问题的统一框架，主要的工作是提出了一种基于图卷积神经网络(GCN)和偏微分方程变分结构的框架，选择的图结构是Chebyshev谱图卷积算子，损失函数是Galerkin变分公式，加上一些稀疏的观测数据，这样能够同时解决正问题和逆问题，这个方法可以处理非结构化网格的不规则区域。</p>
<h2 id="文章链接">2. 文章链接</h2>
<p><a href="https://arxiv.org/abs/2107.12146" title="&quot;Physics-informed graph neural Galerkin networks: A unified framework for solving PDE-governed forward and inverse problems&quot;">physics-informed graph neural Galerkin networks: A unified framework for solving PDE-governed forward and inverse problems</a></p>
<h2 id="作者">3. 作者</h2>
<p><strong><font color="blue">Han Gao, Matthew J. Zahr, Jian-Xun Wang</font></strong></p>
<h2 id="出版杂志及日期">4. 出版杂志及日期</h2>
<p><strong><font color="oran"><a href="https://arxiv.org/abs/2107.12146">arXiv:2107.12146</a> [cs.CE] 16 Jul 2021</font></strong></p>
<h2 id="摘要">5. 摘要</h2>
<p>尽管物理信息神经网络(physics-informed neural networks, PINN)在解决正、逆问题方面有着巨大的前景，但在更复杂和现实的应用中，仍然存在一些技术挑战。<strong>首先</strong>，现有的PINN大多数基于全连接网络的逐点公式来学习连续函数，这导致可扩展性差(poor scalability)和硬边界执行(hard boundary enforcement)。<strong>第二</strong>，无限搜索空间使网络训练的非凸优化问题过于复杂。<strong>第三</strong>，虽然基于卷积神经网络(convolutional neural network, CNN)的离散学习可以显著提高训练效率，但CNN难以使用非结构网格处理不规则几何。为了更好的解决这些问题，我们提出了<strong>一种基于图卷积网络(GCN)和偏微分方程(PDE)变分结构的离散PINN框架</strong>，以统一的形式求解正、逆偏微分方程(PDE)。采用分段多项式基可以降低搜索空间的维度，便于训练和收敛。该方法不需要调整经典PINN的惩罚参数，可以严格限制边界条件，并在正、逆条件下同化稀疏数据(assimilate sparse data)。GCNs的灵活性被用于使用非结构化网格的不规则几何图形。在线性偏微分方程和非线性偏微分方程的正、逆计算力学问题上，证明了该方法的有效性和优越性。</p>
<p><strong>关键字</strong> ：偏微分方程，逆问题，物理信息机器学习(Physics-informed machine learning)，图卷积神经网络，力学(Mechanics)</p>
<h2 id="总结">6. 总结</h2>
<p>本文提出了一种新的离散PINN框架，用于统一求解偏微分方程的正，逆问题。该方法结合了<strong>图卷积网络(GCNs)和物理信息损失函数的Galerkin变分公式</strong>，可以自然地处理具有非结构化网格的不规则区域，并且训练效率提高由于多项式使得搜索空间减少。由于边界条件强(the hard enforcement of boundary conditions)，观测数据稀疏，该方法不需要调整惩罚参数，具有较好的鲁棒性。对线性和非线性偏微分方程正、反问题的数值计算结果表明了所提方法的有效性。此外，作者认为这项工作有助于促进科学深度学习和经典数值技术的健康结合，而不是相互隔离。</p>
<h2 id="贡献">7. 贡献</h2>
<p>本文提出了一种新颖的基于图卷积神经网络和偏微分方程变分结构的离散PINN框架，统一求解偏微分方程的正解和逆解。具体而言，新贡献总结如下：</p>
<ul>
<li>我们将<strong>图卷积运算</strong>引入到物理知识学习中，以充分利用基于有限元的离散化力量来处理具有非结构网格的不规则区域。与基于经典CNN的最先进的离散PINN不同，该方法不需要栅格化(rasterization)，因为它可以像传统有限元求解器那样直接处理带有单纯型/四边形（simplex/quadrilateral）单元的非结构化网格。</li>
<li>在Galerkin公式的基础上，利用一组有限维多项式基函数来重构基于输出节点解图(based on the output nodal solution graph)的全局预测，从而大大减少搜索空间，便于训练。此外，由于两个测试/实验函数都是基于标准多项式的，因此可以使用高斯求积准确地计算变分积分。</li>
<li>所提出的PINN被设计成完全满足基本边界条件，避免了惩罚系数在大多数带有软边界执行的PINNs(PINNs with a soft BC enforcement)调整。</li>
<li>提出了一种新的数据吸收方案来严格执行观测数据</li>
</ul>
<h2 id="实验">8. 实验</h2>
<p>我们在正和逆设置的各种计算力学问题上演示了提出的物理信息图Galerkin神经网络(physics-informed graph Galerkin neural network, PI-GCN)。具体地，本文研究了已知或位置BCs/参数的泊松方程，线性弹性方程和Navier-Stokes方程，以证明所提方法的有效性。此外，我们还比较了两种不同的同化稀疏观测数据的方法，展示了严格强制数据(strictly enforcing data)对参数/域反演的优势。在所有的情况下，GCN架构保持不变，隐藏图层中的节点向量维数固定为[32,64,128,256,128,64,32]。相对误差度量<span class="math inline">\(e\)</span>被定义为： <span class="math display">\[
e=\frac{\left\|\hat{U}\left(\Theta^{*}\right)-U(\bar{\mu})\right\|_{2}}{\|U(\bar{\mu})\|_{2}}
\]</span> 其中<span class="math inline">\(\Theta^{*}\)</span>为参数配置<span class="math inline">\(\bar{\mu}\)</span>计算的最优训练参数。</p>
<h3 id="泊松方程">8.1 泊松方程</h3>
<p>我们从一个二维齐次泊松方程开始，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211017172845.png#" style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(u\)</span>为主变量，<span class="math inline">\(f\)</span>为源项(source term)，<span class="math inline">\(\Delta\)</span>为Laplacian算子。</p>
<h4 id="扩散域的正解forward-solution-of-diffusion-field">8.1.1 扩散域的正解(Forward solution of diffusion field)</h4>
<p>我们首先考虑正问题，其中源项<span class="math inline">\(f\)</span>是给定的(<span class="math inline">\(f=1\)</span>)在一个单位方域（图2a和图2b）。采用四边形单元对三阶多项式基进行离散化以求解和邻域转换(for sloution domain transformation)。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211017190359.png" /></p>
<p><strong>图2</strong>：正方形（a）和圆盘形（c）上扩散场<span class="math inline">\(u\)</span> 的PI-GGN正向解，与相应的有限元法或解析解相比，这里的相对预测误差PI-GGN分别是<span class="math inline">\(e=5 \times 10^{-3}\)</span>在方形域上和<span class="math inline">\(e=5 \times 10^{-4}\)</span>在圆盘上。</p>
<p>结果，图的总节点为49个，远低于典型逐点FC-PINN的配置点总数。PI-GGN预测轮廓与有限元参考轮廓吻合较好，相对误差<span class="math inline">\(e=0.5\%\)</span>，但在边界附近有轻微的低估。在图2c中，相同的偏微分方程在单位圆域上求解，其中存在解析解（图2d）,</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211017213701.png" style="zoom:50%;" /></p>
<p>在PI-GGN中，元素个数不变，多项式基的阶为2，使用25个节点来构造图。我们可以看到PI-GGN正解与分析参考几乎相同，相对预测误差<span class="math inline">\(e\)</span>仅为<span class="math inline">\(0.05\%\)</span>。这个简单的测试用例说明了基于图离散化PINN可以很容易地处理带有非结构化网格的非矩形域，这对标准的基于FD的CNN架构提出了挑战，标准的基于FD的CNN架构，光栅化或坐标转换等特殊处理是被需要的，使实现复杂化和收敛。</p>
<h3 id="未知源的逆解inverse-solution-of-unknown-source-term">8.1.2 未知源的逆解（Inverse solution of unknown source term）</h3>
<p>PI-GGN真正的威力在于通过吸收额外的状态观测同时解决正、逆问题。例如，当源项未给出时，PI-GGN能够同化稀疏数据求解扩散场，同时统一推断未知源项。在这里，我们假设常数源项<span class="math inline">\(f=2\)</span>是未知的，并且<span class="math inline">\(u\)</span>只能在图3a所示的一点上观测到。我们使用两种方法来吸收源项和解决逆问题：一是同化数据通过添加数据损失作为一个惩罚项(公式15)，其中超参数选为<span class="math inline">\(\lambda=1000\)</span>，另一个是同化数据严格基于公式17。正如图3b所示，两种方法推导出的源项都收敛到基本事实(ground truth)，同时也得到了<span class="math inline">\(u\)</span>场的正解。总体而言，未知源项和扩散场的预测误差均小于<span class="math inline">\(1\%\)</span>。</p>
<h2 id="线性弹性方程">8.2 线性弹性方程</h2>
<p>接下来我们考虑由线性弹性方程控制的问题，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211017221447.png" style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(u: \Omega \rightarrow \mathbb{R}^d\)</span>为位移矢量，<span class="math inline">\(\sigma: \Omega \rightarrow \mathbb{R}^{d \times d}\)</span>为应力张量(stress tensor)由<span class="math inline">\(\sigma_{i j}=\lambda u_{k k} \delta_{i j}+\mu\left(u_{i j}+u_{j, i}\right)\)</span>所定义，$ n: ^{d}$为边界上的单位法向量。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211017222336.png" /></p>
<p><strong>图3：</strong> 源项<span class="math inline">\(f\)</span>的PI-GGN逆解由吸收观测到的扩散数据（黑点），使用（1）惩罚方法（橘色）和（2）硬执行(hard enforcement)（蓝色）,与基本的事实作比较(黑色虚线)，给出了软（橘色虚线）和硬（蓝色虚线）数据吸收预测的误差。</p>
<p>$ t: ^N <sup>{d}<span class="math inline">\(是应用牵力(applied traction force)，\)</span>u</sup>D:^D ^{d}<span class="math inline">\(为基本边界条件，\)</span><span class="math inline">\(和\)</span><span class="math inline">\(是常数Lame参数。对于每个变量组件\)</span>u_i$，为预测构造一个子GCN。</p>
<h4 id="位移场的解">8.2.1 位移场的解</h4>
<p>首先，我们在单位方域内解正问题。为了离散该域，我们使用四个四边形元素，并将求解和域变换的多项式基的阶数设置为2，得到一个25节点图。Lame参数设置为<span class="math inline">\(\lambda=1\)</span>和<span class="math inline">\(\mu=1\)</span>。左边(x=0)规定基本边界条件<span class="math inline">\(u=[0,0]\)</span>，右边(x=0)规定的自然边界条件<span class="math inline">\(t=[0.5,0]\)</span>。图4展示的是位移场的PI-GGN解与有限元参考非常吻合。</p>
<p>然后我们研究一个不规则的区域，一个带有缺口的矩形，其中相同的Lame参数被指定。用55个一阶多项式的单纯形元对该域进行离散，得到其解和域变换。基本边界条件<span class="math inline">\(u^D = [0,0]\)</span>施加在左边界<span class="math inline">\(x=-0.4\)</span>，自然边界条件<span class="math inline">\(t_1=0.5\)</span>设定在右边界。如上述所述，PI-GGN不需要特殊处理，以处理具有单纯形网格的不规则几何。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018141923.png" style="zoom:67%;" /></p>
<p><strong>图4：</strong> 位移场<span class="math inline">\(u\)</span>的PI-GGN的解，与对应的FEM参考比较，PI-GGN的相对预测误差为<span class="math inline">\(e=5 \times 10^{-2}\)</span>.</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018142307.png" style="zoom:67%;" /></p>
<p><strong>图5：</strong> 位移场<span class="math inline">\(u\)</span>的PI-GGN的解，与对应的FEM相比，PI-GGN的相对预测误差为<span class="math inline">\(e=5 \times 10^{-3}\)</span>.</p>
<p>图5展示了PI-GGN的正解是准确的（与FEM求出来的解作比较）</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018142825.png" style="zoom:67%;" /></p>
<p><strong>图6</strong> :位移场<span class="math inline">\(u\)</span>的PI-GGN的解，与对应的FEM参考比较，PI-GGN的相对预测误差为<span class="math inline">\(e=5 \times 10^{-2}\)</span>.</p>
<p>最后，我们考虑3-D邻域。特别地，采用PI-GGN算法求解了三维空心圆柱体的变形。基本边界条件<span class="math inline">\(u^D=[0,0,0]\)</span>施加在左表面，Neuman边界条件<span class="math inline">\(t=-n\)</span>规定在圆柱体内表面<span class="math inline">\((x^2+y^2=1)\)</span>，<span class="math inline">\(t=[0,0,-0.25]\)</span>施加在右表面。采用二阶多项式的基，采用二阶多项式基，六面体单元个数为40个，节点440个。Lame参数设置为<span class="math inline">\(\lambda=0.73\)</span>和<span class="math inline">\(\mu=0.376\)</span>。PI-GGN的位移正解与有限元参考值相当吻合，尽管PI-GGN稍微高估了了圆柱右端的位移（图6）.</p>
<h4 id="未知物质性质的逆解">3.2.2 未知物质性质的逆解</h4>
<p>接下来，我们解决一个由线性弹性方程（式2.1）控制的逆问题。假设Lame参数（<span class="math inline">\(\lambda\)</span>和<span class="math inline">\(\mu\)</span>）是未知的，其真值设为<span class="math inline">\(\lambda=1\)</span>和<span class="math inline">\(\mu=1\)</span>。在图7(a)中随机选择5个点观察位移场。整个位移场通过PI-GGN得到，并且可以准确地推断出Lame参数（图7c和7d）。通过吸收数据以一种硬方式，PI-GGN预测的位移场的相对误差为0.05，略低于惩罚法预测的位移场(<span class="math inline">\(e=0.01\)</span>)，如图7b所示。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018163227.png" style="zoom:80%;" /></p>
<p><strong>图7：</strong> 吸收观测位移数据后的Lame参数PI-GGN的反解，使用（1）惩罚法（橘色）和(2)硬执行法(蓝色)，与真正数据(黑色虚线)进行比较，其中给出了软（橘色虚线）和硬(蓝色虚线)数据吸收的场预测误差。</p>
<h3 id="navier-stokes-方程">3.3 Navier-Stokes 方程</h3>
<p>在最后一个测试案例中，我们研究了由静态不可压缩Navier-Stokes方程的正、逆问题。稳定的NS方程模型是粘性流体在恒定密度下的流动，可以表示为：</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018164019.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(v:\Omega \rightarrow \mathbb{R}^d\)</span>是速度矢量，<span class="math inline">\(p:\Omega \rightarrow \mathbb{R}\)</span>是压强，<span class="math inline">\(\nu\)</span>是流体的黏度，<span class="math inline">\(n:\partial\Omega \rightarrow \mathbb{R}^d\)</span>是到边界的单位外法向量。解变量由<span class="math inline">\(u=[v_1,v_2,p]\)</span>表示。黏度设置为<span class="math inline">\(\nu=0.01\)</span>。处于稳定性考虑，采用吻合单元近似[43]。为预测每个解变量<span class="math inline">\(v_1\)</span>，<span class="math inline">\(v_2\)</span>，<span class="math inline">\(p\)</span>，构建了一个可分离的子网(separate sub-net)。</p>
<h3 id="速度和压力场的正解">3.3.1 速度和压力场的正解</h3>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/image-20211018165018375.png" style="zoom:67%;" /></p>
<p><strong>图8：</strong> 速度大小和压力场PI-GGN的解，与相应的FEM参考相比较，其中速度预测的相对误差为<span class="math inline">\(8.7 \times 10^{-3}\)</span>，压力预测的相对误差为<span class="math inline">\(1.95 \times 10^{-2}\)</span>。</p>
<p>首先，我们在一个经典流动问题上测试了所提出的方法，盖子驱动的空腔流动，定义在一个方形域。盖子放置在顶部边缘并向右移动<span class="math inline">\((v_1=1,v_2=0)\)</span>。其余三条边设为无滑移壁(no-slip walls)<span class="math inline">\((v_1=0,v_2=0)\)</span>。区域由100个四边形单元离散。速度和压力场的配置点分别为441和121个。PI-GGN的速度和压力正解的轮廓与相应的FEM参考很好地吻合，如图8所示。相对误差小于1%。值得注意的是，为了达到基于AD的相同精度水平，使用了超过10000个配置点[16,17]。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018182413.png" style="zoom:80%;" /></p>
<p><strong>图9：</strong> 速度大小和压力场PI-GGN的解，与相应的FEM参考相比较，其中速度预测的相对误差为<span class="math inline">\(4.4 \times 10^{-3}\)</span>，压力预测的相对误差为<span class="math inline">\(1.8 \times 10^{-2}\)</span>。</p>
<p>我们还测试PI-GGN解决流体流动在一个理想化的狭窄，入口速度设置为<span class="math inline">\(v^D=[0,1]\)</span>在底部（<span class="math inline">\(y=0\)</span>）和没有牵力边界条件规定的出口在顶部<span class="math inline">\((y=0)\)</span>。盖驱动腔问题采用了相同的有限元设置。同样地，速度场和压力场都能得到准确的求解，PI-GGN预测结果与有限元参考结果吻合较好。</p>
<h4 id="未知进口速度场和未观测到的压力场的反解">3.3.2 未知进口速度场和未观测到的压力场的反解</h4>
<p>最后，我们考虑一个由NS方程控制的逆问题。其中，假设入口速度场未知，通过吸收稀疏速度场观测数据推断入口速度场，如图10b所示。真正的入口有一个抛物线轮廓，如图10e所示。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018184806.png" style="zoom:80%;" /></p>
<p><strong>图10：</strong> 随机选取19个点吸收观测速度数据的入口速度场(the inlet velocity field) PI-GGN逆解。推导出的入口数据的相对误差采用软惩罚法为<span class="math inline">\(e=0.4\)</span>，然而采用硬强制法(hard enforcement approach)为<span class="math inline">\(e=0.04\)</span>。</p>
<p>在求解逆问题时，没有预先定义侧面的函数形式(the functional form of the profile)。也就是，反转的维度(the dimension of inversion)等于入口的自由度，它们是大于20的。该方法通过吸收稀疏位置的速度观测数据，可以准确推断出未知的入口速度分布，并能很好地恢复整个速度场和压力场。然而，我们发现，基于惩罚的数据吸收方法推断的入口并不十分准确，这明显偏离了基本事实。尽管使用了与前面相同的惩罚系数，但推理性能明显下降。提出的数据吸收方法避免了超参数调优，具有良好的鲁棒性。</p>
<h2 id="方法">9. 方法</h2>
<h3 id="综述">9.1 综述</h3>
<p>考虑一个有界域中的物理系统<span class="math inline">\((\Omega \subset \mathbb{R}^d)\)</span>，由一组具有一般离散形式的非线性、稳态参数化偏微分方程控制，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018191226.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(\mu \in \mathbb{R}^{N_\mu}\)</span>是PDE向量参数，<span class="math inline">\(U:\mathbb{R}^{N_\mu} \rightarrow \mathbb{R}^{N_U}\)</span>是隐式定义(1)的解的离散参数相关状态向量，<span class="math inline">\(R:\mathbb{R}^{N_U} \times \mathbb{R}^{N_\mu} \rightarrow \mathbb{R}^{N_U}\)</span>表示离散PDE算子。PDE集受到边界条件(BCs)的约束，这些条件是在域的边界<span class="math inline">\(\partial\Omega\)</span>上定义的。在这项工作中，我们提出了一种创新的物理图神经Galerkin 网络(PI-GGN)，以建立一种解决这种PDE控制的系统在正反两种情况的方法。在正问题中，我们的目标是在已知BCs和参数的情况下得到解<span class="math inline">\(U\)</span>；逆问题为在BCs和参数都部分已知的情况下求解，而观测状态是稀疏的。在该框架中，设计了一个GCN来学习一组非结构化网格上的状态节点解。基于连续Galerkin方法重构了物理信息损失函数中的偏微分方程残差。该方法对系统的基本BCs进行了硬性设置，并吸收了额外的数据以同时解决正和逆问题。提出方法的每个部分将在下面的子节中详细说明。</p>
<h3 id="非结构化数据的图卷积神将网络">9.2 非结构化数据的图卷积神将网络</h3>
<p>由于GCN在处理非结构化数据方面具有极大的灵活性，因此在科学机器学习问题中应用GCN的兴趣日益浓厚。在通过经典的数据驱动训练对各种计算力学问题建模时，已有报道称基于图的学习表现出色[34-39]。一般来说，GCNs通过定义非欧式空间的卷积操作，将CNN类型的构造推广到图数据。对图节点之间的依赖关系进行建模的能力是GCN能够处理任意边界的非结构化网格数据的关键。如图1所示，图由节点和边组成，其中每个节点由其特征向量<span class="math inline">\(f\)</span>定义，与其他节点的关系由边描述。一个节点的邻居<span class="math inline">\(\mathcal{N}(\cdot)\)</span>是指通过边与该节点相连的相邻节点的集合。因此，具有非结构化网格和相应节点的PDE解的网格可以自然地用图来描述。类似于基于CNN离散PINN[20]，构建GCN来建模离散解域<span class="math inline">\(U(\bar{\mu}) \approx \hat{U}\left(\Theta^{*}\right)\)</span>，其中<span class="math inline">\(\Theta^{*}\)</span>为GCN的训练参数对于参数<span class="math inline">\(\bar{\mu}\)</span>的图卷积。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018201300.png" style="zoom:80%;" /></p>
<p><strong>图1：</strong> GCN的一个例子，其中输入/输出图有3个节点和边，以及相同的邻接矩阵<span class="math inline">\(\mathcal{N}(1)=\{2，3\}，\mathcal{N}(2)=\{1，3\}，\mathcal{N}(3)=\{1，2\}\)</span>。输入特征是每个节点的坐标<span class="math inline">\((f_i^{in}=x_i)\)</span>，输出特征为节点解向量<span class="math inline">\((f_i^{out}=u_i(x_i))\)</span>。</p>
<p><strong>注记：</strong> 由于深度神经网络具有普遍近似能力，一般情况下，GCN的输入特征向量可以是网格离散的任意空间变化的场。在本文中，GCN取一个输入图，其中每个节点与其网格的空间坐标相关联，然后将离散化的解场输出为输出图，其中每个节点包含包含相应的节点向量场。</p>
<p>与CNN相似，输出解图是通过对输入层进行多个图卷积操作，通过消息传递函数依次更新节点特征得到的，可以写成通用形式，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018211116.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(i\)</span>表示<span class="math inline">\(i^{th}\)</span>节点，<span class="math inline">\((l)\)</span>代表<span class="math inline">\(l^{th}\)</span>层，<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\Psi\)</span>是可微的非线性函数，<span class="math inline">\(\square\)</span>表示可微的置换不变函数（例如：求和，平均值，最大值）。特征向量表示为<span class="math inline">\(f_{i}^{(l)} \in \mathbb{R}^{N_{f^{(l)}}}\)</span>和<span class="math inline">\(f_{i}^{(l-1)} \in \mathbb{R}^{N_{f^{(l-1)}}}\)</span>，其中<span class="math inline">\(N_{f^{(l-1)}}\)</span>和<span class="math inline">\(N_{f^{(l)}}\)</span>是特征维数分别在<span class="math inline">\((l-1)^{th}\)</span>和<span class="math inline">\(l^{th}\)</span>层。为了实现的简单性，所有的节点特征通常被连接并平展成一个更大的向量<span class="math inline">\(x\)</span>。边缘连接的信息储存在一个稀疏矩阵<span class="math inline">\(A\)</span>中，称为邻接矩阵。在这项工作中，GCN是基于Chebyshev谱图卷积算子[40]，这是由谱卷积定理推导出的，引入Chebyshev多项式以避免昂贵的特征分解。具体地说，Chebyshev图卷积的消息传递函数可以写成，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018212758.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(\Theta^{(l-1,k)}\)</span>为在<span class="math inline">\((l-1)^{th}\)</span>层第<span class="math inline">\(k\)</span>个基的可训练参数，<span class="math inline">\(b^{(l-1)}\)</span>是一个附加的可训练的偏置向量，第<span class="math inline">\(k\)</span>个基<span class="math inline">\(Z^{(l-1,k)}\)</span>递归计算如下，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018213419.png" style="zoom:67%;" /></p>
<p>并且</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018213614.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(I\)</span>是单位矩阵，<span class="math inline">\(D\)</span>代表的是图的度矩阵。修正的线性单元(the rectified linear unit，ReLU)作为非线性激活函数和多项式阶<span class="math inline">\(K\)</span>设置为10，在本文中。</p>
<h3 id="变分pde信息损失函数">9.3 变分PDE信息损失函数</h3>
<p>基于PDE残差(公式1)构建损失函数，使得利用守恒定律通知/驱动GCN训练。用于稳定状态场景的通用PDE可以重写为，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018214748.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(u: \Omega \rightarrow \mathbb{R}^{N_c}\)</span>为解变量，<span class="math inline">\(F: \mathbb{R}^{N_c} \rightarrow \mathbb{R}^{N_c \times d}\)</span>为通量函数(the flux function)，<span class="math inline">\(S: \mathbb{R}^{N_c} \rightarrow \mathbb{R}^{N_c}\)</span>为源项(source term)，<span class="math inline">\(\triangledown := (\partial_{x_1},...,\partial_{x_d})\)</span>为在物理域中定义的梯度算子。公式6能够代表广泛的静态偏微分方程，如泊松方程，线性弹性方程，Navier-Stokes方程。</p>
<h4 id="pde残差的弱形式">9.3.1 PDE残差的弱形式</h4>
<p>对于连续的FC-PINN，采用自动微分以逐点的方式得到构造PDE信息损失函数的导数项，FCNN是一个连续的实验函数(continuous trial function )搜索无穷维的解空间。因此，无限的搜索空间使得网络训练的非凸优化变得过于复杂，通常需要大量的配置点。在这项工作中，我们使用一个分段多项式基来减少搜索空间的维度，并促进基于物理的训练/收敛。其中，守恒律(公式6)采用节点连续Galerkin方法离散，实验空间<span class="math inline">\(\nu_h^p\)</span>采用连续分段多项式基函数构造，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018221815.png" style="zoom:67%;" /></p>
<p>其中，<span class="math inline">\(\mathcal{H}^1(\Omega)\)</span>表示Sobolev空间，其中1阶一下的弱导数是平方可积的，<span class="math inline">\(\mathcal{P}_p(K)\)</span>是在元素<span class="math inline">\(K\)</span>上定义的次数为<span class="math inline">\(p\)</span>的多项式函数空间，<span class="math inline">\(\varepsilon_h\)</span>为有限元网格。测试空间设为与实验空间<span class="math inline">\(\nu_h^p\)</span>相同，解<span class="math inline">\(u_h \in \nu_h^p\)</span>满足任意测试函数<span class="math inline">\(\omega_h \in \nu_h^p\)</span>的偏微分方程的弱公式，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018222838.png" style="zoom:67%;" /></p>
<p>我们为<span class="math inline">\(\nu_h^p\)</span>引进一个基<span class="math inline">\(\Phi(x) \in \mathbb{R}^{N_U \times N_c}\)</span>，将测试变量表示为<span class="math inline">\(\omega_h(x)=\Phi(x)^T \tilde{W}\)</span>，其中$  ^{N_U}$为基上测试变量系数，利用测试函数系数的任意性便引出了Galerkin形式的等效版本</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/image-20211018223817605.png" style="zoom:67%;" /></p>
<p>我们通过引入<span class="math inline">\(\left\{\left(\beta_{i}^{v}, \tilde{x}_{i}^{v}\right)\right\}_{i=1}^{N_{q v}}\)</span> 和<span class="math inline">\(\left\{\left(\beta_{i}^{s}, \tilde{x}_{i}^{s}\right)\right\}_{i=1}^{N_{s v}}\)</span>作为求积权重和积分点分别在在<span class="math inline">\(\Omega\)</span>和<span class="math inline">\(\partial \Omega\)</span>将其转换为残差形式，将残差定义为</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018224737.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(\tilde{u}_h:\Omega \times \mathbb{R}^{N_U} \rightarrow \mathbb{R}^{N_c}\)</span>是离散状态向量在<span class="math inline">\(\nu_h^p\)</span>的连续表示，即</p>
<p>表面和体积的求积系数(<span class="math inline">\(\beta ^s\)</span>和<span class="math inline">\(\beta ^v\)</span>)储存为常张量，并在网络训练过程中保持不变。基函数<span class="math inline">\(\Phi\)</span>是在有限的求积点上得到的矩阵，可以预先计算为常张量<span class="math inline">\(\left(\phi\left(\tilde{x}^{v}\right), \phi\left(\tilde{x}^{s}\right), \nabla \phi\left(\tilde{x}^{v}\right), \nabla \phi\left(\tilde{x}^{s}\right)\right)\)</span>偏微分方程残差的变分公式（公式10）将用于定义GCN的物理信息损失函数。也就是说，该节点解向量<span class="math inline">\(\tilde{U}\)</span>能够被GCN学习为输出图<span class="math inline">\(\hat{U}(\Theta)\)</span>，输出图以坐标<span class="math inline">\(\chi\)</span>作为输入图。当PDE参数<span class="math inline">\(\mu\)</span>未知时，可将其视为可训练参数，随着网络参数<span class="math inline">\(\Theta\)</span>一起更新。通量和源函数<span class="math inline">\((F,S)\)</span>都是可微函数，其梯度信息可以从输出传播到它们的输入。表1总结了这些符号。</p>
<h4 id="基本边界条件执行essential-boundary-condition-enforcement">9.3.2 基本边界条件执行(Essential boundary condition enforcement)</h4>
<p>我们通过限制不受约束的自由度(例如，远离基本边界条件的自由度)来应用静态冷凝(static condensation)到(10)，</p>
<p>其中<span class="math inline">\(U_e\)</span>为基本边界条件的已知值，<span class="math inline">\(U_u(\mu)\)</span>为<span class="math inline">\(U(\mu)\)</span>对于的不受约束自由度的指标。在神经网络设置中，我们通过划分自由度到不受限（未知）和受限（已知）的自由度即<span class="math inline">\(\hat{U}(\Theta)=\left(\hat{U}_{u}(\Theta)^{\top}, \hat{U}_{c}^{\top}\right)^{\top}\)</span>来强化基本边界条件和定义约束自由度使用基本边界条件已知的值，即<span class="math inline">\(\hat{U}_c=U_e\)</span>。</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019094452.png" style="zoom:80%;" /></p>
<p>通过最小化物理信息损失函数来定义无约束自由度，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019095029.png" style="zoom:67%;" /></p>
<p>在这个公式中，与连续的FC-PINN将FCNN定义为逐点的解函数不同，该公式通过构造自动满足基本边界条件，在硬边界执行方面存在挑战。</p>
<h3 id="统一正解和逆解">9.4 统一正解和逆解</h3>
<p>GCN可以根据公式13定义的物理信息损失函数进行训练，通过求解以下不带标签的优化问题，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019101426.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(\Theta^*\)</span>为最佳的网络参数，<span class="math inline">\(\bar{\mu}\)</span>为已知的PDE参数，然后使用GCN来求解PDE(正解)。然而在很多情况下，一些物理参数如材料性质，进口速度。雷诺数等式无法观测得到的，而可以得到稀疏的观测数据(标签)<span class="math inline">\(U_o\)</span>，并将其吸收来推断未知参数(逆解)。在之前的PINN方法中，逆问题可以通过软方式吸收数据<span class="math inline">\(U_o\)</span>来解决，其中物理信息损失通过数据损失组件来增强。即得到如下优化：</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019102751.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(\mathcal{F}^{s2o}\)</span>表示状态到可观测的映射(the state-to-observable map)，<span class="math inline">\(\lambda\)</span>为惩罚参数。适当调整惩罚权重<span class="math inline">\(\lambda\)</span>是收敛的关键，然而这是具有挑战性的，经常执行经验主义地[16]。在本文中，介绍了一种新的方法，在不需要超参数调整的情况下，吸收观测数据并推断未知参数。具体来说，将GCN的输出构造为严格的观测数据：</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019104247.png" style="zoom:67%;" /></p>
<p>因此，通过求解一下约束优化问题，可以同时得到未知参数<span class="math inline">\(\mu\)</span>和边界条件<span class="math inline">\(\hat{U}_u\)</span>以及PDE的解<span class="math inline">\(\hat{U}_u\)</span>，</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019104640.png" style="zoom:67%;" /></p>
<h2 id="介绍introduction">10 介绍（Introduction）</h2>
<p>​</p>
<h2 id="方法梳理">11 方法梳理</h2>
<p>这篇文章提出了一种基于图卷积神经网络(GCN)和偏微分方程变分结构的框架，其中图结构：</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018211116.png" style="zoom:67%;" /></p>
<p>具体的图结构，使用的是Chebyshev谱图卷积算子：</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211018212758.png" style="zoom:67%;" /></p>
<p>损失函数：</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019102751.png" style="zoom:67%;" /></p>
<p>其中</p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019101426.png" style="zoom:67%;" /></p>
<p><img src="https://guodongsanjianke.oss-cn-beijing.aliyuncs.com/pictures/20211019095029.png" style="zoom:67%;" /></p>
<p>这样既可以解正问题又可以解反问题。</p>
<p>下面再介绍一下Galerkin方法</p>
<h4 id="galerkin方法">Galerkin方法</h4>
<p><a href="https://baike.baidu.com/item/%E4%BC%BD%E8%BE%BD%E9%87%91%E6%B3%95/165767">Galerkin法</a>是一种数值分析方法，采用微分方程对应的弱形式，其原理为通过选取有限多项式函数(又称基函数或形函数)，将他们叠加，再要求结果再求解域内及边界上的加权积分满足原方程，便可以得到一组易于求解的线性代数方程，且自然边界条件能够满足。</p>
<p>Galerkin方法通过方程对应泛函的变分原理将求解微分方程问题简化为线性方程组的求解问题。而一个多为（多变量）的线性方程组又可以通过线性代数方法简化，从而达到求解微分方程的目的。Galerkin法通过选取有限多项式的基函数，将他们叠加，再要求结果在求解域内及边界上的加权积分满足原方程，便可以得到一组易于求解的线性代数方程，且自然边界条件能够自动满足。作为一种试探函数选取形式，Galerkin法所得到的只是在原求解域内的一个近似解，仅仅是加权平均满足原方程，并非在每个点上都满足。</p>
<p>考虑定义域为<span class="math inline">\(V\)</span>的控制方程，其一般表达式为： <span class="math display">\[
L_u=P
\]</span> 精确解集<span class="math inline">\(u\)</span>上的每一点都满足上述方程，如果我们寻找一个近似解<span class="math inline">\(\bar{u}\)</span>，它必然会带来一个误差<span class="math inline">\(\varepsilon\)</span>，把它叫做残差，即 <span class="math display">\[
\varepsilon(x) = L_\bar{u}-P
\]</span> 近似方法要求残差经加权后他在整个区域之和应为0，即： <span class="math display">\[
\int_ V\left[W_{i}\left(L_{\bar{u}}-p\right)\right] d V=0
\]</span> 其中<span class="math inline">\(i=1,2,..,n\)</span>。选取不同的加权函数<span class="math inline">\(W_i\)</span>会得到不同的近似方法。</p>
<p>对于Galerkin方法来说，加权函数<span class="math inline">\(W_i\)</span>一般称为形函数（基函数），<span class="math inline">\(\Phi\)</span>的形式为<span class="math inline">\(\Phi=\sum\Phi_i \cdot G_i\)</span>，其中<span class="math inline">\(G_i\)</span><span class="math inline">\((i=1,2,...,n)\)</span>为基底函数<span class="math inline">\(\Phi_i\)</span>为待求系数，这里将加权函数取为基底<span class="math inline">\(G_i\)</span>的线性组合。</p>
<p>另外一般的近似解<span class="math inline">\(\bar{u}\)</span>的构造也是选取<span class="math inline">\(G_i\)</span>为基底函数，即${u}=_i G_i <span class="math inline">\(，其\)</span>_i$中为待定系数。</p>
<p>综上可得Galerkin的表达形式如下：</p>
<p>选择基底函数<span class="math inline">\(G_i\)</span>，确定${u}=_i G_i <span class="math inline">\(中的系数\)</span>_i$使得</p>
<p><span class="math display">\[
\int_ V\left[\Phi \left(L_{\bar{u}}-p\right)\right] d V=0
\]</span> 对于<span class="math inline">\(\Phi=\sum\Phi_i \cdot G_i\)</span>类型的每一个函数<span class="math inline">\(\Phi\)</span>都成立，其中系数<span class="math inline">\(\Phi_i\)</span>是待定的，但需要满足其边界条件。求解出<span class="math inline">\(\mathcal{Q}_i\)</span>之后，就能得到近似解<span class="math inline">\(\bar{u}\)</span>。</p>
<p><span class="math display">\[
\left\{\begin{array}{l}
\begin{aligned}
\frac{u_{j}^{n+1}-u_{j}^{n}}{\Delta t} &amp;=\left(\frac{x}{b_{t}} \frac{b_{t}^{n+1}-b_{t}^{n}}{\Delta t} \ln x+\frac{x}{b_t} \frac{b_{t}^{n+1}-b_{t}^{n}}{\Delta t}+\frac{1}{2} \frac{x}{b_{t}^{2}}-\frac{x}{b_{t}}\right) \frac{u_{j+1}^{n}-u_{j}^{n}}{\Delta x}
+ \frac{1}{2} \frac{x^{2}}{b^{2}_ t} \frac{u_{j+1}^{n}-2 u_{j}^{n}+u_{j-1}^{n}}{(\Delta x)^{2}}
\end{aligned}, x \in (0,1],t&gt;0 \\
u(x, t)=0, x \in(1, \infty), t &gt;0 \\
u(x, 0)=f_{0}\left(b_{t} \ln x+b_{t}\right), \quad x \in(0, \infty) \\
G(t)=b_{t} \int_{0}^{1} \frac{u(x, t)}{x} d x,t \geqslant 0
\end{array}\right.
\]</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Graph neural network</tag>
      </tags>
  </entry>
</search>
